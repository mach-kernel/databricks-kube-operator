use schemars::JsonSchema;
/*
 * Jobs API 2.1
 *
 * The Jobs API allows you to create, edit, and delete jobs. You should never hard code secrets or store them in plain text. Use the [Secrets API](https://docs.databricks.com/dev-tools/api/latest/secrets.html) to manage secrets in the [Databricks CLI](https://docs.databricks.com/dev-tools/cli/index.html). Use the [Secrets utility](https://docs.databricks.com/dev-tools/databricks-utils.html#dbutils-secrets) to reference secrets in notebooks and jobs.
 *
 * The version of the OpenAPI document: 2.1
 *
 * Generated by: https://openapi-generator.tech
 */

/// RunLifeCycleState : * `PENDING`: The run has been triggered. If there is not already an active run of the same job, the cluster and execution context are being prepared. If there is already an active run of the same job, the run immediately transitions into the `SKIPPED` state without preparing any resources. * `RUNNING`: The task of this run is being executed. * `TERMINATING`: The task of this run has completed, and the cluster and execution context are being cleaned up. * `TERMINATED`: The task of this run has completed, and the cluster and execution context have been cleaned up. This state is terminal. * `SKIPPED`: This run was aborted because a previous run of the same job was already active. This state is terminal. * `INTERNAL_ERROR`: An exceptional state that indicates a failure in the Jobs service, such as network failure over a long period. If a run on a new cluster ends in the `INTERNAL_ERROR` state, the Jobs service terminates the cluster as soon as possible. This state is terminal. * `NO_RUNS`: Used as a default status in databricks-kube-operator for additionalPrinterColumns presentation.

/// * `PENDING`: The run has been triggered. If there is not already an active run of the same job, the cluster and execution context are being prepared. If there is already an active run of the same job, the run immediately transitions into the `SKIPPED` state without preparing any resources. * `RUNNING`: The task of this run is being executed. * `TERMINATING`: The task of this run has completed, and the cluster and execution context are being cleaned up. * `TERMINATED`: The task of this run has completed, and the cluster and execution context have been cleaned up. This state is terminal. * `SKIPPED`: This run was aborted because a previous run of the same job was already active. This state is terminal. * `INTERNAL_ERROR`: An exceptional state that indicates a failure in the Jobs service, such as network failure over a long period. If a run on a new cluster ends in the `INTERNAL_ERROR` state, the Jobs service terminates the cluster as soon as possible. This state is terminal. * `NO_RUNS`: Used as a default status in databricks-kube-operator for additionalPrinterColumns presentation.
#[derive(
    JsonSchema, Clone, Copy, Debug, Eq, PartialEq, Ord, PartialOrd, Hash, Serialize, Deserialize,
)]
pub enum RunLifeCycleState {
    #[serde(rename = "TERMINATED")]
    Terminated,
    #[serde(rename = "PENDING")]
    Pending,
    #[serde(rename = "RUNNING")]
    Running,
    #[serde(rename = "TERMINATING")]
    Terminating,
    #[serde(rename = "SKIPPED")]
    Skipped,
    #[serde(rename = "INTERNAL_ERROR")]
    InternalError,
    #[serde(rename = "NO_RUNS")]
    NoRuns,
}

impl ToString for RunLifeCycleState {
    fn to_string(&self) -> String {
        match self {
            Self::Terminated => String::from("TERMINATED"),
            Self::Pending => String::from("PENDING"),
            Self::Running => String::from("RUNNING"),
            Self::Terminating => String::from("TERMINATING"),
            Self::Skipped => String::from("SKIPPED"),
            Self::InternalError => String::from("INTERNAL_ERROR"),
            Self::NoRuns => String::from("NO_RUNS"),
        }
    }
}

impl Default for RunLifeCycleState {
    fn default() -> RunLifeCycleState {
        Self::Terminated
    }
}
