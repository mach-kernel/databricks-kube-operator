use schemars::JsonSchema;
/*
 * Jobs API 2.1
 *
 * The Jobs API allows you to create, edit, and delete jobs. You should never hard code secrets or store them in plain text. Use the [Secrets API](https://docs.databricks.com/dev-tools/api/latest/secrets.html) to manage secrets in the [Databricks CLI](https://docs.databricks.com/dev-tools/cli/index.html). Use the [Secrets utility](https://docs.databricks.com/dev-tools/databricks-utils.html#dbutils-secrets) to reference secrets in notebooks and jobs.
 *
 * The version of the OpenAPI document: 2.1
 *
 * Generated by: https://openapi-generator.tech
 */

/// ClusterEventType : * `CREATING`: Indicates that the cluster is being created. * `DID_NOT_EXPAND_DISK`: Indicates that a disk is low on space, but adding disks would put it over the max capacity. * `EXPANDED_DISK`: Indicates that a disk was low on space and the disks were expanded. * `FAILED_TO_EXPAND_DISK`: Indicates that a disk was low on space and disk space could not be expanded. * `INIT_SCRIPTS_STARTING`: Indicates that the cluster scoped init script has started. * `INIT_SCRIPTS_FINISHED`: Indicates that the cluster scoped init script has finished. * `STARTING`: Indicates that the cluster is being started. * `RESTARTING`: Indicates that the cluster is being started. * `TERMINATING`: Indicates that the cluster is being terminated. * `EDITED`: Indicates that the cluster has been edited. * `RUNNING`: Indicates the cluster has finished being created. Includes the number of nodes in the cluster and a failure reason if some nodes could not be acquired. * `RESIZING`: Indicates a change in the target size of the cluster (upsize or downsize). * `UPSIZE_COMPLETED`: Indicates that nodes finished being added to the cluster. Includes the number of nodes in the cluster and a failure reason if some nodes could not be acquired. * `NODES_LOST`: Indicates that some nodes were lost from the cluster. * `DRIVER_HEALTHY`: Indicates that the driver is healthy and the cluster is ready for use. * `DRIVER_UNAVAILABLE`: Indicates that the driver is unavailable. * `SPARK_EXCEPTION`: Indicates that a Spark exception was thrown from the driver. * `DRIVER_NOT_RESPONDING`: Indicates that the driver is up but is not responsive, likely due to GC. * `DBFS_DOWN`: Indicates that the driver is up but DBFS is down. * `METASTORE_DOWN`: Indicates that the driver is up but the metastore is down. * `NODE_BLACKLISTED`: Indicates that a node is not allowed by Spark. * `PINNED`: Indicates that the cluster was pinned. * `UNPINNED`: Indicates that the cluster was unpinned.

/// * `CREATING`: Indicates that the cluster is being created. * `DID_NOT_EXPAND_DISK`: Indicates that a disk is low on space, but adding disks would put it over the max capacity. * `EXPANDED_DISK`: Indicates that a disk was low on space and the disks were expanded. * `FAILED_TO_EXPAND_DISK`: Indicates that a disk was low on space and disk space could not be expanded. * `INIT_SCRIPTS_STARTING`: Indicates that the cluster scoped init script has started. * `INIT_SCRIPTS_FINISHED`: Indicates that the cluster scoped init script has finished. * `STARTING`: Indicates that the cluster is being started. * `RESTARTING`: Indicates that the cluster is being started. * `TERMINATING`: Indicates that the cluster is being terminated. * `EDITED`: Indicates that the cluster has been edited. * `RUNNING`: Indicates the cluster has finished being created. Includes the number of nodes in the cluster and a failure reason if some nodes could not be acquired. * `RESIZING`: Indicates a change in the target size of the cluster (upsize or downsize). * `UPSIZE_COMPLETED`: Indicates that nodes finished being added to the cluster. Includes the number of nodes in the cluster and a failure reason if some nodes could not be acquired. * `NODES_LOST`: Indicates that some nodes were lost from the cluster. * `DRIVER_HEALTHY`: Indicates that the driver is healthy and the cluster is ready for use. * `DRIVER_UNAVAILABLE`: Indicates that the driver is unavailable. * `SPARK_EXCEPTION`: Indicates that a Spark exception was thrown from the driver. * `DRIVER_NOT_RESPONDING`: Indicates that the driver is up but is not responsive, likely due to GC. * `DBFS_DOWN`: Indicates that the driver is up but DBFS is down. * `METASTORE_DOWN`: Indicates that the driver is up but the metastore is down. * `NODE_BLACKLISTED`: Indicates that a node is not allowed by Spark. * `PINNED`: Indicates that the cluster was pinned. * `UNPINNED`: Indicates that the cluster was unpinned.
#[derive(
    JsonSchema, Clone, Copy, Debug, Eq, PartialEq, Ord, PartialOrd, Hash, Serialize, Deserialize,
)]
pub enum ClusterEventType {
    #[serde(rename = "CREATING")]
    Creating,
    #[serde(rename = "DID_NOT_EXPAND_DISK")]
    DidNotExpandDisk,
    #[serde(rename = "EXPANDED_DISK")]
    ExpandedDisk,
    #[serde(rename = "FAILED_TO_EXPAND_DISK")]
    FailedToExpandDisk,
    #[serde(rename = "INIT_SCRIPTS_STARTING")]
    InitScriptsStarting,
    #[serde(rename = "INIT_SCRIPTS_FINISHED")]
    InitScriptsFinished,
    #[serde(rename = "STARTING")]
    Starting,
    #[serde(rename = "RESTARTING")]
    Restarting,
    #[serde(rename = "TERMINATING")]
    Terminating,
    #[serde(rename = "EDITED")]
    Edited,
    #[serde(rename = "RUNNING")]
    Running,
    #[serde(rename = "RESIZING")]
    Resizing,
    #[serde(rename = "UPSIZE_COMPLETED")]
    UpsizeCompleted,
    #[serde(rename = "NODES_LOST")]
    NodesLost,
    #[serde(rename = "DRIVER_HEALTHY")]
    DriverHealthy,
    #[serde(rename = "DRIVER_UNAVAILABLE")]
    DriverUnavailable,
    #[serde(rename = "SPARK_EXCEPTION")]
    SparkException,
    #[serde(rename = "DRIVER_NOT_RESPONDING")]
    DriverNotResponding,
    #[serde(rename = "DBFS_DOWN")]
    DbfsDown,
    #[serde(rename = "METASTORE_DOWN")]
    MetastoreDown,
    #[serde(rename = "NODE_BLACKLISTED")]
    NodeBlacklisted,
    #[serde(rename = "PINNED")]
    Pinned,
    #[serde(rename = "UNPINNED")]
    Unpinned,
}

impl ToString for ClusterEventType {
    fn to_string(&self) -> String {
        match self {
            Self::Creating => String::from("CREATING"),
            Self::DidNotExpandDisk => String::from("DID_NOT_EXPAND_DISK"),
            Self::ExpandedDisk => String::from("EXPANDED_DISK"),
            Self::FailedToExpandDisk => String::from("FAILED_TO_EXPAND_DISK"),
            Self::InitScriptsStarting => String::from("INIT_SCRIPTS_STARTING"),
            Self::InitScriptsFinished => String::from("INIT_SCRIPTS_FINISHED"),
            Self::Starting => String::from("STARTING"),
            Self::Restarting => String::from("RESTARTING"),
            Self::Terminating => String::from("TERMINATING"),
            Self::Edited => String::from("EDITED"),
            Self::Running => String::from("RUNNING"),
            Self::Resizing => String::from("RESIZING"),
            Self::UpsizeCompleted => String::from("UPSIZE_COMPLETED"),
            Self::NodesLost => String::from("NODES_LOST"),
            Self::DriverHealthy => String::from("DRIVER_HEALTHY"),
            Self::DriverUnavailable => String::from("DRIVER_UNAVAILABLE"),
            Self::SparkException => String::from("SPARK_EXCEPTION"),
            Self::DriverNotResponding => String::from("DRIVER_NOT_RESPONDING"),
            Self::DbfsDown => String::from("DBFS_DOWN"),
            Self::MetastoreDown => String::from("METASTORE_DOWN"),
            Self::NodeBlacklisted => String::from("NODE_BLACKLISTED"),
            Self::Pinned => String::from("PINNED"),
            Self::Unpinned => String::from("UNPINNED"),
        }
    }
}

impl Default for ClusterEventType {
    fn default() -> ClusterEventType {
        Self::Creating
    }
}
