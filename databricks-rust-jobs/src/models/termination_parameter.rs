use schemars::JsonSchema;
/*
 * Jobs API 2.1
 *
 * The Jobs API allows you to create, edit, and delete jobs. You should never hard code secrets or store them in plain text. Use the [Secrets API](https://docs.databricks.com/dev-tools/api/latest/secrets.html) to manage secrets in the [Databricks CLI](https://docs.databricks.com/dev-tools/cli/index.html). Use the [Secrets utility](https://docs.databricks.com/dev-tools/databricks-utils.html#dbutils-secrets) to reference secrets in notebooks and jobs.
 *
 * The version of the OpenAPI document: 2.1
 * 
 * Generated by: https://openapi-generator.tech
 */




#[derive(JsonSchema, Clone, Debug, PartialEq, Serialize, Deserialize)]
pub struct TerminationParameter {
    /// The username of the user who terminated the cluster.
    #[serde(rename = "username", skip_serializing_if = "Option::is_none")]
    pub username: Option<String>,
    /// The AWS provided error code describing why cluster nodes could not be provisioned. For example, `InstanceLimitExceeded` indicates that the limit of EC2 instances for a specific instance type has been exceeded. For reference, see: <https://docs.aws.amazon.com/AWSEC2/latest/APIReference/query-api-troubleshooting.html>.
    #[serde(rename = "aws_api_error_code", skip_serializing_if = "Option::is_none")]
    pub aws_api_error_code: Option<String>,
    /// The AWS provided state reason describing why the driver node was terminated. For example, `Client.VolumeLimitExceeded` indicates that the limit of EBS volumes or total EBS volume storage has been exceeded. For reference, see <https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_StateReason.html>.
    #[serde(rename = "aws_instance_state_reason", skip_serializing_if = "Option::is_none")]
    pub aws_instance_state_reason: Option<String>,
    /// Describes why a spot request could not be fulfilled. For example, `price-too-low` indicates that the max price was lower than the current spot price. For reference, see: <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/spot-bid-status.html#spot-instance-bid-status-understand>.
    #[serde(rename = "aws_spot_request_status", skip_serializing_if = "Option::is_none")]
    pub aws_spot_request_status: Option<String>,
    /// Provides additional details when a spot request fails. For example `InsufficientFreeAddressesInSubnet` indicates the subnet does not have free IP addresses to accommodate the new instance. For reference, see <https://docs.aws.amazon.com/cli/latest/reference/ec2/describe-spot-instance-requests.html>.
    #[serde(rename = "aws_spot_request_fault_code", skip_serializing_if = "Option::is_none")]
    pub aws_spot_request_fault_code: Option<String>,
    /// The AWS provided status check which failed and induced a node loss. This status may correspond to a failed instance or system check. For reference, see <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/monitoring-system-instance-status-check.html>.
    #[serde(rename = "aws_impaired_status_details", skip_serializing_if = "Option::is_none")]
    pub aws_impaired_status_details: Option<String>,
    /// The AWS provided scheduled event (for example reboot) which induced a node loss. For reference, see <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/monitoring-instances-status-check_sched.html>.
    #[serde(rename = "aws_instance_status_event", skip_serializing_if = "Option::is_none")]
    pub aws_instance_status_event: Option<String>,
    /// Human-readable context of various failures from AWS. This field is unstructured, and its exact format is subject to change.
    #[serde(rename = "aws_error_message", skip_serializing_if = "Option::is_none")]
    pub aws_error_message: Option<String>,
    /// Additional context that may explain the reason for cluster termination. This field is unstructured, and its exact format is subject to change.
    #[serde(rename = "databricks_error_message", skip_serializing_if = "Option::is_none")]
    pub databricks_error_message: Option<String>,
    /// An idle cluster was shut down after being inactive for this duration.
    #[serde(rename = "inactivity_duration_min", skip_serializing_if = "Option::is_none")]
    pub inactivity_duration_min: Option<String>,
    /// The ID of the instance that was hosting the Spark driver.
    #[serde(rename = "instance_id", skip_serializing_if = "Option::is_none")]
    pub instance_id: Option<String>,
    /// The ID of the instance pool the cluster is using.
    #[serde(rename = "instance_pool_id", skip_serializing_if = "Option::is_none")]
    pub instance_pool_id: Option<String>,
    /// The [error code](https://docs.databricks.com/dev-tools/api/latest/clusters.html#clusterterminationreasonpoolclusterterminationcode) for cluster failures specific to a pool.
    #[serde(rename = "instance_pool_error_code", skip_serializing_if = "Option::is_none")]
    pub instance_pool_error_code: Option<String>,
}

impl TerminationParameter {
    pub fn new() -> TerminationParameter {
        TerminationParameter {
            username: None,
            aws_api_error_code: None,
            aws_instance_state_reason: None,
            aws_spot_request_status: None,
            aws_spot_request_fault_code: None,
            aws_impaired_status_details: None,
            aws_instance_status_event: None,
            aws_error_message: None,
            databricks_error_message: None,
            inactivity_duration_min: None,
            instance_id: None,
            instance_pool_id: None,
            instance_pool_error_code: None,
        }
    }
}


