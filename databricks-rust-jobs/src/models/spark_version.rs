use schemars::JsonSchema;
/*
 * Jobs API 2.1
 *
 * The Jobs API allows you to create, edit, and delete jobs. You should never hard code secrets or store them in plain text. Use the [Secrets API](https://docs.databricks.com/dev-tools/api/latest/secrets.html) to manage secrets in the [Databricks CLI](https://docs.databricks.com/dev-tools/cli/index.html). Use the [Secrets utility](https://docs.databricks.com/dev-tools/databricks-utils.html#dbutils-secrets) to reference secrets in notebooks and jobs.
 *
 * The version of the OpenAPI document: 2.1
 * 
 * Generated by: https://openapi-generator.tech
 */




#[derive(JsonSchema, Clone, Debug, PartialEq, Serialize, Deserialize)]
pub struct SparkVersion {
    /// [Databricks Runtime version](https://docs.databricks.com/dev-tools/api/latest/index.html#programmatic-version) key, for example `7.3.x-scala2.12`. The value that must be provided as the `spark_version` when creating a new cluster. The exact runtime version may change over time for a “wildcard” version (that is, `7.3.x-scala2.12` is a “wildcard” version) with minor bug fixes.
    #[serde(rename = "key", skip_serializing_if = "Option::is_none")]
    pub key: Option<String>,
    /// A descriptive name for the runtime version, for example “Databricks Runtime 7.3 LTS”.
    #[serde(rename = "name", skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
}

impl SparkVersion {
    pub fn new() -> SparkVersion {
        SparkVersion {
            key: None,
            name: None,
        }
    }
}


