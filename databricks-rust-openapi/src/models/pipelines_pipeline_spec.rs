use schemars::JsonSchema;
/*
 * Databricks Accounts and Workspace REST API on ALL
 *
 * No description provided (generated by Openapi Generator https://github.com/openapitools/openapi-generator)
 *
 * The version of the OpenAPI document: 1.0.0
 * 
 * Generated by: https://openapi-generator.tech
 */




#[derive(JsonSchema, Clone, Debug, PartialEq, Serialize, Deserialize)]
pub struct PipelinesPipelineSpec {
    /// Whether the pipeline is in Development mode. Defaults to false.
    #[serde(rename = "development", skip_serializing_if = "Option::is_none")]
    pub development: Option<bool>,
    #[serde(rename = "libraries", skip_serializing_if = "Option::is_none")]
    pub libraries: Option<Vec<crate::models::PipelinesPipelineLibrary>>,
    /// Whether Photon is enabled for this pipeline.
    #[serde(rename = "photon", skip_serializing_if = "Option::is_none")]
    pub photon: Option<bool>,
    /// DBFS root directory for storing checkpoints and tables.
    #[serde(rename = "storage", skip_serializing_if = "Option::is_none")]
    pub storage: Option<String>,
    #[serde(rename = "clusters", skip_serializing_if = "Option::is_none")]
    pub clusters: Option<Vec<crate::models::PipelinesPipelineCluster>>,
    /// Unique identifier for this pipeline.
    #[serde(rename = "id", skip_serializing_if = "Option::is_none")]
    pub id: Option<String>,
    /// String-String configuration for this pipeline execution.
    #[serde(rename = "configuration", default, skip_serializing_if = "Option::is_none")]
    pub configuration: Option<::std::collections::HashMap<String, String>>,
    /// Filters on which Pipeline packages to include in the deployed graph.
    #[serde(rename = "filters", skip_serializing_if = "Option::is_none")]
    pub filters: Option<Box<crate::models::PipelinesFilters>>,
    /// Friendly identifier for this pipeline.
    #[serde(rename = "name", skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// Pipeline product edition.
    #[serde(rename = "edition", skip_serializing_if = "Option::is_none")]
    pub edition: Option<String>,
    /// Target schema (database) to add tables in this pipeline to. If not specified, no data is published to the Hive metastore or Unity Catalog. To publish to Unity Catalog, also specify `catalog`.
    #[serde(rename = "target", skip_serializing_if = "Option::is_none")]
    pub target: Option<String>,
    /// DLT Release Channel that specifies which version to use.
    #[serde(rename = "channel", skip_serializing_if = "Option::is_none")]
    pub channel: Option<String>,
    /// Whether the pipeline is continuous or triggered. This replaces `trigger`.
    #[serde(rename = "continuous", skip_serializing_if = "Option::is_none")]
    pub continuous: Option<bool>,
    /// Which pipeline trigger to use. Deprecated: Use `continuous` instead.
    #[serde(rename = "trigger", skip_serializing_if = "Option::is_none")]
    pub trigger: Option<Box<crate::models::PipelinesPipelineTrigger>>,
    /// A catalog in Unity Catalog to publish data from this pipeline to. If `target` is specified, tables in this pipeline are published to a `target` schema inside `catalog` (for example, `catalog`.`target`.`table`). If `target` is not specified, no data is published to Unity Catalog.
    #[serde(rename = "catalog", skip_serializing_if = "Option::is_none")]
    pub catalog: Option<String>,
    /// Whether serverless compute is enabled for this pipeline.
    #[serde(rename = "serverless", skip_serializing_if = "Option::is_none")]
    pub serverless: Option<bool>,
}

impl PipelinesPipelineSpec {
    pub fn new() -> PipelinesPipelineSpec {
        PipelinesPipelineSpec {
            development: None,
            libraries: None,
            photon: None,
            storage: None,
            clusters: None,
            id: None,
            configuration: None,
            filters: None,
            name: None,
            edition: None,
            target: None,
            channel: None,
            continuous: None,
            trigger: None,
            catalog: None,
            serverless: None,
        }
    }
}


