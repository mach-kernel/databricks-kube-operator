use schemars::JsonSchema;
/*
 * Databricks Accounts and Workspace REST API on ALL
 *
 * No description provided (generated by Openapi Generator https://github.com/openapitools/openapi-generator)
 *
 * The version of the OpenAPI document: 1.0.0
 * 
 * Generated by: https://openapi-generator.tech
 */




#[derive(JsonSchema, Clone, Debug, PartialEq, Serialize, Deserialize)]
pub struct ComputeClusterLogConf {
    /// destination needs to be provided. Eg. `{ \"dbfs\" : { \"destination\" : \"dbfs:/home/cluster_log\" } }`
    #[serde(rename = "dbfs", skip_serializing_if = "Option::is_none")]
    pub dbfs: Option<Box<crate::models::ComputeDbfsStorageInfo>>,
    /// destination and either the region or endpoint need to be provided. Eg. `{ \"s3\": { \"destination\" : \"s3://cluster_log_bucket/prefix\", \"region\" : \"us-west-2\" } }` Cluster iam role is used to access s3, please make sure the cluster iam role in `instance_profile_arn` has permission to write data to the s3 destination.
    #[serde(rename = "s3", skip_serializing_if = "Option::is_none")]
    pub s3: Option<Box<crate::models::ComputeS3StorageInfo>>,
}

impl ComputeClusterLogConf {
    pub fn new() -> ComputeClusterLogConf {
        ComputeClusterLogConf {
            dbfs: None,
            s3: None,
        }
    }
}


