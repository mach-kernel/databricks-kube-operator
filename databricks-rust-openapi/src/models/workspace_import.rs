use schemars::JsonSchema;
/*
 * Databricks Accounts and Workspace REST API on ALL
 *
 * No description provided (generated by Openapi Generator https://github.com/openapitools/openapi-generator)
 *
 * The version of the OpenAPI document: 1.0.0
 * 
 * Generated by: https://openapi-generator.tech
 */




#[derive(JsonSchema, Clone, Debug, PartialEq, Serialize, Deserialize)]
pub struct WorkspaceImport {
    /// The base64-encoded content. This has a limit of 10 MB.  If the limit (10MB) is exceeded, exception with error code **MAX_NOTEBOOK_SIZE_EXCEEDED** is thrown. This parameter might be absent, and instead a posted file is used. 
    #[serde(rename = "content", skip_serializing_if = "Option::is_none")]
    pub content: Option<String>,
    #[serde(rename = "format", skip_serializing_if = "Option::is_none")]
    pub format: Option<crate::models::WorkspaceImportFormat>,
    #[serde(rename = "language", skip_serializing_if = "Option::is_none")]
    pub language: Option<crate::models::WorkspaceLanguage>,
    /// The flag that specifies whether to overwrite existing object. It is `false` by default. For `DBC` format, `overwrite` is not supported since it may contain a directory.
    #[serde(rename = "overwrite", skip_serializing_if = "Option::is_none")]
    pub overwrite: Option<bool>,
    /// The absolute path of the object or directory. Importing a directory is only supported for the `DBC` format.
    #[serde(rename = "path")]
    pub path: String,
}

impl WorkspaceImport {
    pub fn new(path: String) -> WorkspaceImport {
        WorkspaceImport {
            content: None,
            format: None,
            language: None,
            overwrite: None,
            path,
        }
    }
}


