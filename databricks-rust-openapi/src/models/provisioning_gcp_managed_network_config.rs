use schemars::JsonSchema;
/*
 * Databricks Accounts and Workspace REST API on ALL
 *
 * No description provided (generated by Openapi Generator https://github.com/openapitools/openapi-generator)
 *
 * The version of the OpenAPI document: 1.0.0
 * 
 * Generated by: https://openapi-generator.tech
 */

/// ProvisioningGcpManagedNetworkConfig : The network settings for the workspace. The configurations are only for Databricks-managed VPCs. It is ignored if you specify a customer-managed VPC in the `network_id` field.\", All the IP range configurations must be mutually exclusive. An attempt to create a workspace fails if Databricks detects an IP range overlap.  Specify custom IP ranges in CIDR format. The IP ranges for these fields must not  overlap, and all IP addresses must be entirely within the following ranges: `10.0.0.0/8`, `100.64.0.0/10`, `172.16.0.0/12`, `192.168.0.0/16`, and `240.0.0.0/4`.  The sizes of these IP ranges affect the maximum number of nodes for the workspace.  **Important**: Confirm the IP ranges used by your Databricks workspace before creating the workspace. You cannot change them after your workspace is deployed. If the IP address ranges for your Databricks are too small, IP exhaustion can occur, causing your Databricks jobs to fail. To determine the address range sizes that you need, Databricks provides a calculator as a Microsoft Excel spreadsheet. See [calculate subnet sizes for a new workspace](https://Docsgcp.databricks.com/administration-guide/cloud-configurations/gcp/network-sizing.html). 



#[derive(JsonSchema, Clone, Debug, PartialEq, Serialize, Deserialize)]
pub struct ProvisioningGcpManagedNetworkConfig {
    /// The IP range from which to allocate GKE cluster pods. No bigger than `/9` and no smaller than `/21`.
    #[serde(rename = "gke_cluster_pod_ip_range", skip_serializing_if = "Option::is_none")]
    pub gke_cluster_pod_ip_range: Option<String>,
    /// The IP range from which to allocate GKE cluster services. No bigger than `/16` and no smaller than `/27`.
    #[serde(rename = "gke_cluster_service_ip_range", skip_serializing_if = "Option::is_none")]
    pub gke_cluster_service_ip_range: Option<String>,
    /// The IP range from which to allocate GKE cluster nodes. No bigger than `/9` and no smaller than `/29`.
    #[serde(rename = "subnet_cidr", skip_serializing_if = "Option::is_none")]
    pub subnet_cidr: Option<String>,
}

impl ProvisioningGcpManagedNetworkConfig {
    /// The network settings for the workspace. The configurations are only for Databricks-managed VPCs. It is ignored if you specify a customer-managed VPC in the `network_id` field.\", All the IP range configurations must be mutually exclusive. An attempt to create a workspace fails if Databricks detects an IP range overlap.  Specify custom IP ranges in CIDR format. The IP ranges for these fields must not  overlap, and all IP addresses must be entirely within the following ranges: `10.0.0.0/8`, `100.64.0.0/10`, `172.16.0.0/12`, `192.168.0.0/16`, and `240.0.0.0/4`.  The sizes of these IP ranges affect the maximum number of nodes for the workspace.  **Important**: Confirm the IP ranges used by your Databricks workspace before creating the workspace. You cannot change them after your workspace is deployed. If the IP address ranges for your Databricks are too small, IP exhaustion can occur, causing your Databricks jobs to fail. To determine the address range sizes that you need, Databricks provides a calculator as a Microsoft Excel spreadsheet. See [calculate subnet sizes for a new workspace](https://Docsgcp.databricks.com/administration-guide/cloud-configurations/gcp/network-sizing.html). 
    pub fn new() -> ProvisioningGcpManagedNetworkConfig {
        ProvisioningGcpManagedNetworkConfig {
            gke_cluster_pod_ip_range: None,
            gke_cluster_service_ip_range: None,
            subnet_cidr: None,
        }
    }
}


