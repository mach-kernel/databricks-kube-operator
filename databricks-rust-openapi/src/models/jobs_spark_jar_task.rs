use schemars::JsonSchema;
/*
 * Databricks Accounts and Workspace REST API on ALL
 *
 * No description provided (generated by Openapi Generator https://github.com/openapitools/openapi-generator)
 *
 * The version of the OpenAPI document: 1.0.0
 * 
 * Generated by: https://openapi-generator.tech
 */




#[derive(JsonSchema, Clone, Debug, PartialEq, Serialize, Deserialize)]
pub struct JobsSparkJarTask {
    /// Deprecated since 04/2016. Provide a `jar` through the `libraries` field instead. For an example, see :method:jobs/create. 
    #[serde(rename = "jar_uri", skip_serializing_if = "Option::is_none")]
    pub jar_uri: Option<String>,
    /// The full name of the class containing the main method to be executed. This class must be contained in a JAR provided as a library.  The code must use `SparkContextgetOrCreate` to obtain a Spark context; otherwise, runs of the job fail.
    #[serde(rename = "main_class_name", skip_serializing_if = "Option::is_none")]
    pub main_class_name: Option<String>,
    #[serde(rename = "parameters", skip_serializing_if = "Option::is_none")]
    pub parameters: Option<Vec<String>>,
}

impl JobsSparkJarTask {
    pub fn new() -> JobsSparkJarTask {
        JobsSparkJarTask {
            jar_uri: None,
            main_class_name: None,
            parameters: None,
        }
    }
}


